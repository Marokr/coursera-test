{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCEEY1nnh5tt"
      },
      "source": [
        "# 0. შესავალი\n",
        "\n",
        "ალბათ ყველას გყავთ (თუ თქვენ თვითონ არ ხართ) ისეთი მეგობარი, რომელიც ცოტა გამაღიზიანებელი სიმარტივით ხსნის ტექნიკურ პრობლემებს. თუ არ გყავთ ასეთი მეგობარი და არც თვითონ ხართ არ იდარდოთ, რადგან ამ წიგნის ბოლოს დაუმეგორდებით მონაცემთა ანალიტიკის და „მანქანური დასწავლის“ ალგორითმებსა და ხელსაწყოებს, რომლებიც იმაზე უფრო სწრაფად და უფრო რთულ პრობლემებს გადაგაჭრევინებთ ვიდრე წარმოგიდგენიათ.\n",
        " \n",
        "მონაცემები დღევანდელი, ციფრული, სამყაროს განუყოფელი ნაწილია და მათი დამუშავების უნარი ყოველ წელს უფრო და უფრო ღირებული ხდება. მსგავსი კომპეტენციის ადამიანი კი უკლებლივ ყველა ზომის და ინდუსტრუიის კომპანიისთვის საგანძურს წარმოადგენს.\n",
        " \n",
        "სულ რაღაც 5-10 წლის წინ, ორგანიზაციებს უწევდათ დაექირავებინათ სტატისტიკოსები, მათემატიკოსები, კომპიუტერული მეცნიერებების სპეციალისტები და სხვა ტექნიკური უნარების მქონე ადამიანები ძალიან მარტივი ამოცანების გადასაჭრელადაც კი. თუმცა ერთის მხრივ მონაცემთა ანალიზზე მასშტაბურმა მოთხოვნამ და მეორეს მხრივ ტექნოლოგიების მკვერთმა განვითარებამ შედეგად მოგვცა უამრავი მზა ხელსაწყო, რომელთა ათვისებაც არ მოითხოვს დიპლომს სარაკეტო მეცნიერებში. პირიქითაც შეგვიძლია ვთქვათ, დღეს მონაცემების დამუშავება იმდენად ინტეგრირებულია ყველა ინდუსტრიაში, რომ თავიანთი საქმის ექსპერტები შეიარაღებულნი მანქანური დასწავლის და მონაცემთა დამუშავების მეთოდებით  უმეტეს შემთხვევაში გაცილებით მეტ ღირებულებას ქმნიან, ვიდრე მხოლოდ ტექნიკური სპეციალისტები.\n",
        " \n",
        "რა თქმა უნდა არ მოგატყუებთ და არ გეტვით, რომ გიგანტი ორგანიზაციები როგორებიცაა მაგალითად გუგლი, ფეისბუქი, ამაზონი, ფეიფალი და ა.შ. აღარ საჭიროებენ ისეთი კომპეტენციის კადრებს, ვინც საფუძვლიანად ფლობენ მსგავსი ტიპის ალგორითმებს. თუმცა აღნიშნული კომპანიების შემთხვევაშიც კი ხშირად იმაზე გაცილებით მარტივად იჭრება ძვირადღირებული ამოცანები ვიდრე ჩვენ წარმოგვიდგენია. \n",
        " \n",
        "წიგნი განკუთვნილია ყველა იმ ადამიანისთვის ვინც დაინტერესებულია შეიძინოს ანალიტიკური უნარები და თვითონვე, დამოუკიდებლად, შეძლოს მასთან დაკავშირებული ამოცანების გადაჭრა. თუ თქვენ აქამდე ისეთ გავრცელებულ პროგრამასთანაც კი არ გქონიათ შეხება, როგოროცაა „ექსელი“, არ იდარდოთ სწორ ადგილას მოხვდით.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCYIbTYFh5tv"
      },
      "source": [
        "# 1. მონაცემთა ანალიზი და მისი გამოყენება პრაქტიკაში"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RgZjqbLh5tv"
      },
      "source": [
        "### 1.1 მონაცემთა ანალიზის მნიშვნელობა\n",
        "\n",
        "Სანამ ანალიზის ტიპებსა და ალგორითმების ახსნას შევეჭიდებით, Მოგიყვებით ერთ ძალიან საინტერესო ისტორიას, რომელიც ხაზს უსვამს მონაცემთა ანალიტიკის მნიშვნელობას. ეს ისოტორია ცნობილია როგორც აბრაჰამ ვალდის „გადარჩენილების მიკერძოებულობა.“\n",
        "\n",
        "ვალდი 1902 წლის 31 ოქტომბერს, უნგრეთის ქალაქ კოლოსვარში (ახლანდელი კლუჟი, რუმინეთი) ებრაულ ოჯახში დაიბადა. უნგრეთში განათლების მიღება გაუჭირდა, რადგან სწავლა შაბათობით იყო, ხოლო ებრაული ტრადიციების შესაბამისად ეს დასვენების დღეა. თუმცა გამორჩეული ნიჭის მქონე ვალდი ადრეულ ასაკშივე, ვენის უნივერსიტეტში მოხვდა. 1938 წლამდე (სანამ ნაცისტური გერმანია შეიჭრებოდა ვენაში) ავსტიაში ცხოვრება შედარებით უკეთესი იყო. მას შემდეგ კი ალბათ წარმოგიდგენიათ რამდენად გაუსაძლისი გახდა ცხოვრება ახალგაზრდა ებრაელისთვის ნაცისტური გერმანიის მიერ ოკუპირებულ ქვეყანაში. იგი მალევე მიიწვიეს ამერიკის შეერთებულ შტატებში, სადაც შეგვიძლია ვთქვამ რომ მან გაასწრო ნაცისტურ რეჟიმს, რადგან სამწუხაროდ ავსტრიაში დარჩენილი მისი ოჯახის ყველა წევრი დაიღუპა. Აბრაჰამი შტატებში კოლუმბიის უნივერსიტეტში დასაქმდა სადაც ცხოვრების ბოლომდე იმუშავა. \n",
        "\n",
        "1941 წელს უნივერსიტეტში ვალდის მეთაურობით შეიქმნა სტატისტიკოს მკვლევართა ჯგუფი, რომელიც ამერიკის არმიას უნდა დახმარებოდა ბომბდამშენების ჯავშნების ოპტიმიზაციაში. პრობლემა წარმოადგენდა შემდეგს: გერმანული სახმელეთო თავდაცვა გასაოცარი წარმატებით უმკლავდებოდა ამერიკულ თვითმფრინავებს. ვალდს და მის ჯგუფს ამერიკის არიამ მიაწოდა მონაცემები იმის შესახებ თუ სად ქონდათ ყველაზე ხშირად მოხვედრილი ტყვიები გადარჩენილ ბომბდამშენებს."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9iUNTllh5tw"
      },
      "source": [
        "![1.%20Wald.png](attachment:1.%20Wald.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n3vSk6sh5tw"
      },
      "source": [
        "მონაცემებიდან აშკარა იყო რომ ყველაზე მოწყვლადი ადგილები თვითმფრინავის უკანა ნაწილი და ფრთები იყო. დასკვნაც თითქოს მარტივი გამოსატანი ჩანდა, დაემატებინათ ჯავშანი აღნიშნულ ადგილებში. თუმცა აბრაჰამ ვალდმა, სრულიად საპირისპიროდ, ავიაციას მოუწოდა ძრავის გარშემო ადგილი გაეძლიერებიდან. მისი დასკვნა ეფუძნებოდა იმ ფაქტს, რომ ყველა მონაცემი რაც გააჩნდათ იყო ზუსტადაც რომ გადარჩენილი თვითმფრინავების და არა ჩამოვარდნილების. შესაბამისად მისი დაშვებით, თვითმფირანვების ჩამოვარდნის ყველაზე ხშირი მიზეზი ძრავში მორტყმული ტყვიები იყო, რასაც შემდეგ „გადარჩენილების მიკერძოებულობა“ ეწოდა და დღემდე ბევრ სხვადასხვა სფეროში გამოიყენება შეცდომების თავიდან ასარიდებლად. სხვა სიტყვებით რომ ვთქვათ მონაცემებიდან დასკვნების გამოტანამდე, დარწმუნებულებუ უნდა ვიყოთ, რომ ის **არ არის** მიკერძოებული ერთი ტიპის ინფორმაციის მოწოდებაზე."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ukvd5q7nh5tw"
      },
      "source": [
        "### 1.2 Რა არის მონაცემთა ანალიზი და რატომ დღეს \n",
        "\n",
        "იმედი გვაქვს Წინა თავში მოყვანილმა ისტორიულმა მაგალითმა მკითხველს გაუღვივა მონაცემების ანალიზისადმი ინტერესი, თუმცა სანამ უშუალოდ მეთოდების აღწერასა და შესწავლაზე ვისაუბრებთ, ჯერ კარგად განვმარტოთ რას ნიშნავს მონაცემთა ანალიზი და რატომ არის დღეს ასეთი აქტუალური.\n",
        "\n",
        "**მონაცემების მოგროვების, გასუფთავების, კვლევისა და მოდელირების პროცესს, რომელიც ემსახურება ახალი მიგნებების პოვნას და გვეხმარება გადაწყვეტილებების მიღებაში, მონაცემთა ანალიზი ეწოდება. სხვა სიტყვებით, რომ ვთქვათ: ის გვეხმარება გაურკვევლობის შემცირებაში.**\n",
        "\n",
        "დისციპლინა რა თქმა უნდა არ არის ახალი, უკვე საუკუნეებია მონაცემთა ანალიზი გამოიყენება სხვადასხვა სფეროში გადაწყვეტილებების მისაღებად. თუმცა დღეს ის რადიკალურად განსხვავებულია. კომპიუტერების გაჩენასთან ერთად ექსპონენციალურად იზრდება მონაცემების დამუშვების სისწრაფეც და მასზე ხელმისაწვდომობაც.\n",
        "\n",
        "Მაგალითისთვის სურათზე ხედავთ როგორ ხდებოდა მონაცემების მოგროვება (4 მილიონი გამოყენებული ბილეთი) 1939 წელს ლონდონის მეტროს რიგების გასაანალიზებლად."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pb2C6Hssh5tx"
      },
      "source": [
        "![2.%20london.png](attachment:2.%20london.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J81yN9cUh5tx"
      },
      "source": [
        "ეს კი მთლიანი პროცესის მხოლოდ მცირედი ნაწილია. ამას Შემდგომ მოსდევს: მონაცემების სწორად აღრიცხვა, დახარისხება და დამუშავება. ყველაფერი ეს კი მხოლოდ კალმის და ფურცლის გამოყენებით. \n",
        "\n",
        "დღეს მთელი ეს პროცესი გაციფრულებულია: მყისიერად აისახება ყველა ბილეთის შეძენა თუ მრავალჯერადი აბონიმენტის გამოყენება, აწყობილია მზა ანალიტიკური დეშბორდები სადაც შედეგი აისახება და შემდგომ ხდება ამ ანალიზე დაფუძნებით გარკვეული გადაწყვეტილებების მიღება.\n",
        "\n",
        "Პროცესების, დამუშავების და ხელმისაწვდომობის მკვეთრი გაუმჯობესება, როგორც უკვე აღვნიშნეთ თავიდან ბოლომდე კომპიუტერული ტექნოლოგიების დამსახურებაა.\n",
        "\n",
        "##### ერთი კომპიუტერი = ერთი პროგრამა = ერთი მომხმარებელი\n",
        "\n",
        "ალბათ ყველას გინახავთ, როგორ გამოიყურება პირველი კომპიუტერი. გაურკვეველი, უშველებელი მოწყობილობა, რომლესაც მხოლოდ ტრივიალური ამოცანების გადაჭრა შეუძლია და მის გამოსაყენებლად დოქტორის ხარისხიც კი არ კმარა იმდენად კომპლექსურია.\n",
        "\n",
        "##### ერთი კომპიუტერი = N პროგრამა = M მომხმარებელი\n",
        "\n",
        "ტექნოლოგიის განვითარებასთან ერთად ახალი შესაძლებლობები გაჩნდა. ერთ კომპიუტერზე უკვე რამდენიმე პროგრამა ყენდებოდა, თუმცა თავად პროგრამები იმდენად რთულად გამოსაყენებელი იყო, რომ  ისევ თითოეულ მათგანს თავის პროფესიონალი სჭრიდებოდა. Სიჩქარეც რა თქმა უნდა დაიხვეწა თუმცა ჯერ კიდევ შორს იყო დღევანდელი რეალობისგან.\n",
        "\n",
        "##### ერთი კომპიუტერი = N პროგრამა = 1 მომხმარებელი\n",
        "განვითარების შემდეგ ეტაპზე, უკვე ისეთი კომპიუტერები მივიღეთ, რომლითაც ახლა თქვენ ამ წიგნს კითხულობთ (თუ ნაბეჭდ ვერსიას კითხულობთ მაშინ გეტყვით, რომ ასეთ კომპიუტერში დაიბეჭდა ეს წიგნი). Პროგრამები იმდენად დაიხვეწა, რომ დღეს არ არსებობს ადამიანი ვისაც კომპიტერთან შეხება ქონია და რამდენიმე მათგანს თავისუფლად არ იყენებს. Მაგალითდ ვერ ბრაუზერი, ვორდი, ექსელი, ფოტოების დასათვალიერებელი პროგრამები და ა.შ. \n",
        "\n",
        "##### M კომპიუტერი = N პროგრამა = 1 მომხმარებელი\n",
        "\n",
        "Მიუხედავად იმისა, რომ ყოველდღიურ ცხოვრებაში ჯერ კიდევ ლოკალურ კომპიუტერებს მოვიხმართ, გამოთვლითი ტექნოლოგიების თვალსაზრისით სურათი აქ რადიკალურად შეცლილია. კერძოდ, ქლაუდ ტექნოლოგიების დახმარებით დღეს უკვე შესაძლებელია რამდენიმე სუპერ მძლავრ კომპიუტერს ერთდროულად ვიყენებდეთ, სადაც ასევე რამდენიმე პროგრამა იქნება დაყენებული, ეს ყველაფერი კი მხოლოდ ერთმა (არა მაინცდამაინც დოქტორის ხარისხის და გენიალური ნიჭის მქონე ადამიანმა, როგორც ეს საწყის ფაზაში იყო) ადამიანმა დაბრკოლებების გარეშე აკეთოს.\n",
        "\n",
        "ყველა ამ ცვლილებამ მიგვიყვანა იქამდე, რომ ნებისმიერ ადამიანს შეუძლია მილიონობით ჩანაწერიან მონაცემებთან ისეთი სისწრაფით მუშაობა, როგორითაც ადრე 2+2 ოპერაცია ითვლებოდა. Ასევე აღსანიშნავია ის ფაქტიც რომ დღეს მონაცემების შეგროვება ხდება ყოველ ფეხის ნაბიჯზე: სოციალური ქსელი, საბანკო ბარათის ტრანზაქცია, ინტერნეტ ტელევიზია, სხვადასხვა საიტების გამოყენება და ა.შ. Ზუსტად ამიტომ არის დღეს ასეთი აქტუალური მონაცემების დამუშავების მეთოდების ცოდნა, ის ჩვენი ყოველდღიურობაა."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eA5Fys1yh5tx"
      },
      "source": [
        "### 1.3 მონაცემთა ანალიზის ტიპები\n",
        "ამ ეტაპზე ისტორიული გადახვევები საკმარისია, დროა გადავიდეთ საქმეზე და გავეცნოთ ანალიზის ტიპებს, რომელებიც დღეს გამოიყენება. Სხვადასხვა ლიტერატურასა თუ სტატიაში შეხვდებით განსხვავებულ დაყოფას, ჩვენთვის ყველაზე ახლოს გარტნერის განმარტებაა, სადაც ოთხი ძირითადი ნაწილია, დალაგებული მათი სირთულისა და კომპლექსურობის მიხედვით:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhbxd392h5tx"
      },
      "source": [
        "#### 1.3.1 აღწერითი ანალიზი\n",
        "\n",
        "აღწერითი ანალიზი პასუხობს კითხვას - **რა მოხდა?** მისი გამოყენებით ვაანალიზებთ მონაცემებს სხვადასხვა ფაქტორებისა და დროის ჭრილებში. ისტორიული მეტრიკები რომლებზე დაკვირვებაც შეიძლება გვაინტერესებდეს მოიცავს ისეთ მრავალფერვან სპექტრს როგორებიცაა: საშუალო ჩეკის მოცულობა ყოველთვიურად, კოპმანიის მოგება, მომხმარებლების განაწილება ასაკისა და შეძენილი პროდუქტების მიხედვით და ა.შ. Რა თქმა უნდა ეს პროცესი გვეხმარება გამოვიტანოთ დასკვნები, რომლებზე დაყრდნობითაც სამომავლოდ უკეთ წარვმართავთ საქმეს. სხვა სიტყვებით რომ ვთქვათ აღწერითი ანალიზი არის ისტორიული მონაცემების ინტერპრეტაციის პროცესი. Ნებისმიერი ანალიტიკური ამოცანისთვის, აღწერითი ანალიზი არის საწყისი და აუცილებელი ნაბიჯი სწორი გადაწყვეტილებების მისაღებად, თუმცა ხშირ შემთხვევაში ეს საკმარისი არ არის."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKelt6N1h5tx"
      },
      "source": [
        "#### 1.3.2 დიაგნოსტიკური ანალიზი\n",
        "\n",
        "დიაგნოსტიკური ანალიზი პასუხოს კითხვას - **რატომ მოხდა?** Შეგვიძლია ვთქვათ, რომ ის აღწერითი ანალიზის ლოგიკური გაგრძელებაა. Მრავალი სტატისტიკური თუ ალბათური მეთოდის არსებობის მიუხედავად, დიაგნოსტიკური ანალიზის განუყოფელი ნაწილია შინაარსობრივი კვლევა. Რა თქმა უნდა ყველაფერი რაოდენობრივით იწყება როგორებიცაა: ჰიპოთეზების ჩამოყალიბება და შემოწმება, ცვლადებს შორის დამოკიდებულების და მიზეზ შედეგობრიობის დადგენა (ძალიან ხშირად ფიქრობენ, რომ კორელაცია მიზეზ შედეგობრიობასაც ნიშნავს რამაც შეიძლება მნიშნველოვან შეცდომებამდე მიგვიყვანოს), ასევე შეიძლება მაპროგნოზირებელი მოდელებიც (რომელზეც შემდეგ ქვეთავში ვისაუბრებთ) გამოვიყენოთ ხდომილებების ასახსნელად. თუმცა ამ ყველაფერთან ერთად აუცილებელია ამოცანის შინაარსის სიღმისეული ცდონა, გამოცდილება და ალღო იმისათვის რომ მონაცემებზე დაყრდნობით ავხსნათ მოვლენები. ერთის მხრივ კომპლექსურობა ანალიზს ართულებს თუმცა ამავედ დროს მეტ თავდაჯერებულობას გვმატებს გადაწყვეტილებების მიღებაში. Როგორც თავის დასაწყისში აღვნიშნეთ, მონაცემთა ანალიზის არსიც ხომ ისაა რომ მომავლის გაურკვევლობა შეამციროს, ანუ მომავალი გვაინტერესებს და არა წარსული. აღწერითი და დიაგნოსტიკური ანალიზის მთავარი მიზანიც (მაგრამ არა ერთადერთი), წარსულ ხდომილებებზე დაყრდნობით მომავლის მეტი სიზუსტით პროგრნოზირებაა."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31_qUdWkh5ty"
      },
      "source": [
        "#### 1.3.3 მაპროგნოზირებელი ანალიზი\n",
        "\n",
        "მაპროგნოზირებელი ანალიზი პასუხობს კითხვას - **რა მოხდება?** აღნიშნულზე პასუხის წარმატებით გასცემად, ზემოთ მოყვანილი ანალიზის ორივე ტიპი აუცილებელი წინაპირობაა სასურველი შედეგის მისაღებად. თუმცა ხშირ შემთხვევაში საკმარისი ნამდვილად არ არის რისთვისაც მაპროგნოზირებელ ანალიზს ვიყენებთ. Მიზნის მისაღწევად, Მთელი რიგი მოდელები და იარაღებია. ეს წიგნიც სწორადაც ამ და ნაწილობრივ ანალიზის შემდეგ ტიპზე კონცენტრირდება.\n",
        "\n",
        "მომავალ თავებში დეტალურად განვიხილავთ რა ტიპის მოდელები გამოიყენება სხვადასხვა ხდომილებების საპროგნზოდ. კითხვა აქ არ გაწყვიტოთ, რა თქმა უნდა მხოლოდ საუბრით არ შემოვიფაგლებით, პირიქით ყველაზე მეტ დროს მანქანური დასწავლის ალგორითმების რეალურ ცხოვრებაში გამოყენების შესწავლას დავუთმობთ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6tTgiL8h5ty"
      },
      "source": [
        "#### 1.3.4 რეცეპტული (prescriptive) ანალიზი\n",
        "\n",
        "რეცეპტული ანალიზი პასუხობს კითხვას - **რა მოვიმოქმედოთ შემდგომ?** გარკუველი (სასურველი) ალბათობით გქონდეს ხედვა იმაზე თუ რას მოელი მომავალში ფასდაუდებელი ინფორმაციაა, მაგრამ ზოგიერთ შემთხვევაში ეს პირდაპირ არ ითარგმნება იმაში თუ რა ქმედებების გაწევაა ოპტიმალური. Სწორად ამისთვის გამოიყენება რეცეპტული ანალიზი. Სხვა სიტყვებით, რომ ვთქვათ ეს არის პროცესი, რომელიც გვეხმარება შესაძლო სცენარების, არსებული რესურსების, წარსული გამოცდილებისა და მომავლის პროგნოზის გათვალისწინებით მივიღოთ ოპტიმალური გადაწყვეტილებები."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-59Slvqh5ty"
      },
      "source": [
        "უკანასკნელი ორი ანალიზის ტიპი მჭიდროდ გადაჭვულია. ხშირად მათ ერთმანეთშიც ურევენ ან აიგივენებ. ამიტომ Შევეცდებით მაგალითების საფუძველზე უფრო მკაფიოდ ავხსნათ მათ შორის განსხვავებები.\n",
        "Პირველ მაგალითად განვიხილოთ საკრედიტო ბარათების თაღლითობა. Რა თქმა უნდა აქ ამოცანის პირველი ნაწილია წინასწარ გამოვიცნოთ კონკრეტული მომხმარებელების თაღლითობები, რასაც მაპროგონიზრებელი ანალიზის გარკვეული ალგორითმებით ვუპასუხებდით. თუმცა ამოცანა აქ არ სრულდება. Რას ვშვრებით მას მერე რაც ვიცით რომ გარკვეული მომხმარებელები დიდი ალბათობით თაღლითობენ? ყველას ავტომატურად ვუბლოკავთ საკრედიტო ბარათს? კი მაგრამ ხომ ვიცით რომ არ არსებობს 100%-იანი სიზუსტის მოდელი და ბევრ ადამიანს ტყუილად რომ დავუბლოკოთ ბარათზე წვდომა რეპუტაციული რისკიც გასათვალისწინებელია. იქნებ აზრიანია თაღლითობის ალბათობასთან ერთად მის სავარაუდო მოცულობებსაც შევხედოთ? ან ისე ხომ არ არის საქმე, რომ მოდელი რატომღაც ყველა დიდი მოცულობის ტრანზაქციას თაღლითობად აფასებს (შეიძლება ეს 90% შემთხვევაში ასეც იყოს) და მდიდარი კლეინტები ხომ არ უნდა გამოვხშიროთ ბარათის ავტომატური დაბლოკვის პროცესისგან? Მოკლედ რომ ვთქვათ პროგრნოზიდან ოპტიმალური გადაწყვეტილების მიღებამდე კიდევ დიდი გზაა გასავლელი, ბევრი ფაქტორი გასაანალიზებელი და ბევრი სცენარი განსახილველი. ამ ყველაფერს კი ზუსტადაც რეცეპტული ანალიზი (Prescriptive Analytics) კრავს. ანუ მისი დახმარებით საბოლოო ჯამში ვიღებთ ოპტიმალური ქმედებების რეკომენდაციებს.\n",
        "\n",
        "ასევე კარგი მაგალითია თავად რეკომენდაციების სისტემები. ტერმინი შეიძლება ახალია, მაგრამ მას ყველგან ხვდებით: ვიდეოს დასრულებისას youtube თქვენ წარსულ ნახვებსა და გემოვნებაზე დაყრდნობით გირჩევთ შემდეგ ვიდეოებს, ფეისბუქზე ახალი მეგორების დამატების შემოთავაზებებსაც შეხვდებოდით, spotify-ის მომხმარებელი თუ ხართ ხომ საერთოდ ბედნიერი იქნებით ამ ფუნქციონალით. Საკმაოდ მძლავრი და კოპლექსური სისტემებია, რაც საკუთარ თავში მოიცავს როგორც მანქანური დასწავლის ალგორითმს, ასევე მომდევნო ოპტიმალური ქმედებას (ის ხომ თავისით ადგენს რა მოგეწონებათ და მერე გთავაზობთ კიდეც). \n",
        "\n",
        "Იმედი გვაქვს ზემოთ მოყვანილი მაგალითები დაგეხმარათ უკეთ გაგეანალიზებინათ თუ რა სხვაობაა მაპროგნოზირებელ და რეცეპტულ ანალიზის ტიპებს შორის.\n",
        "\n",
        "შეჯამებისთვის გთავაზობთ გარტნერის გრაფიკს და ჩვენს განმარტებებს თუ რა დარგები პასუხობენ შესაბამის ანალიზის ტიპებს:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEhKp4tYh5ty"
      },
      "source": [
        "![3.%20analtics%20types.png](attachment:3.%20analtics%20types.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5aKUT5tVh5ty"
      },
      "source": [
        "### 1.4 მონაცემთა მეცნიერება და მანქანური დასწავლის ალგორითმების ტიპები"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khyYTfj9h5ty"
      },
      "source": [
        "#### 1.4.1 მონაცემთა მეცნიერება\n",
        "ახლა კი მოდით წინა აბზაცებში დაპირებულ, ყველაზე საინტერესო, ნაწილზე გადავიდეთ. Ბოლოსდაბოლოს რა ჯადოქრობაა ეს მონაცემთა მეცნიერება, ან საერთოდ მეცნიერებაა? არა მეცნიერება ნამდვილად არ არის, **ის არის მულტიდისციპლინარულ ცოდნაზე დაფუძნებული მეთოდოლოგია**. Შესაბამისად არც მონაცემთა მეცნიერები არიან ჯადოქრები. ისინი უბრალოდ უკეთესი პროგრამისტები/დეველოპერები არიან ვიდრე სტატისტიკოსები და უკეთესი სტატისტიკოსები ვიდრე პროგრამისტები/დეველოპერები. ამას დაკნინებად ნუ გაიგებთ, Მარტივად კი ჟღერს, თუმცა არც ისეთი მარტივი პროფესიაა, რომელიც საკმაოდ სიღმისეულ ცოდნას მოითხოვს სტატისტიკის, მათემატიკურ მოდელირების, კომპიუტერული მეცნიერებების და ბიზნეს ანალიზის."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cg8bnxf9h5tz"
      },
      "source": [
        "#### 1.4.2 მანქანური დასწავლის ალგორითმის ტიპები\n",
        "სავარაუდოდ ერთი სული გაქვთ როდის გადავალთ პრაქტიკულ ნაწილზე, თუმცა ჯერ ძალიან ზოგადად, შეგრძნების დონეზე, მოგიყვებით თუ რა ტიპის ამოცანები იჭრება მანქანური დასწავლით და რა ტიპის ალგორითმები შეესაბამება მათ. Შემდგომ თავებში კი ამ ყველაფერს უფრო სიღრმისეულად, პრაქტიკული სავარჯიშოებით და ამოცანებით გავივლით.\n",
        "\n",
        "Წიგნის  მიზანი და  ამბიცია ნამდვილად არ არის მკითხველი მონაცემთა მეცნიერად აქციოს. Შესაბამისად ჩვენ მანაქანური დასწავლის მხოლოდ ძირითად ნაწილებს შევეხებით. არ გეგონოთ, რომ რამეს გაკლებთ. ეს ძირითდი ნაწილები რეალური სამყაროს, მეტს თუ არა, 80%-ს ნამდვილად ფარავს.\n",
        "\n",
        "მანქანური დასწავლის ალგორითმები შეგვიძლია 4 მსხვილ მიმართულებად დავყოთ: დაკვირვებითი მოდელები, რაც თავის მხრივ რეგრესიულ და კლასიფიკაციის ტიპებად იშლება, და დაკვირვების გარეშე მოდელები, რომელიც კლასტერირებად და ასოციაციად იშლება."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoTKzmTOh5tz"
      },
      "source": [
        "![4.%20algorithms.png](attachment:4.%20algorithms.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVX63RMFh5tz"
      },
      "source": [
        "##### 1.4.2.1 დაკვირვებითი ალგორითმები\n",
        "დაკვირვებითი მოდელები შეიძლება ითქვას, რომ ყველაზე ინტუიტიურია მანქანურ დასწავლაში. Მოდელს ვაწვდით მონაცემებს მათი შესაბამისი პასუხებით. Შემდგომ კი იგი ცდილობს იპოვნოს ისეთი კანონზომიერებები, რაც მიწოდენული ინფორმაციით სწორი პასუხების პოვნაში დაეხმარება. გამოდის, რომ კომპიუტერს ბევრი კარგი მაგალითის საფუძველზე ვასწავლით ამოცანის ამოხსნას. \n",
        "\n",
        "Მაგალითისთვის გვინდა გამოვიცნოთ დაიგვიანებს თუ არა თვიმფმრინავის რეისი. ამოცანის გადასაჭრელად დაგვჭირდება თითოეულ რეისთან დაკავშირებული წარსული ინფორმაცია: გამოფრენის დრო, გამოფრენის ქალაქი, დანიშნულების ქალაქი, ამინდი გამოფრენის ქალაქიდან, ამინდი დანიშნულების ადგილზე, ავია კომპანიის სახელი და ა.შ. (ამ ცვლადების ერთობლიობას ბევრი სახელით მოიხსენიებენ: **დამოკიდებული ცვლადები, მახასიათებელი ცვალდები, მოდელში შემავალი ცვლადები**) Ხოლო პასუხების მხარეს (**პსუხებს კი: დამოკიდებულ ცვლადებად ან საპროგნოზო ცვალდებად მოიხსენიებენ**) იქნება დაიგვიანა/დროზე მოფრინდა. Მოდელი იპოვნის კანონზომიერებას დამოკიდებულ ცვლადებსა და დაგვიანებას შორის, რის შემდეგაც უკვე მხოლოდ მახასაითებელი ცვლადების საფუძველზე გააკეთებს პროგნოზს: დააგვიანებს რეისი თუ დროზე მოფრინდება. \n",
        "\n",
        "Ზემოთ მოყვანილი მაგალითი კლასიკური **კლასიფიკაციის** ამოცანაა. Მსგავსი ტიპის ამოცანის **მიზანი ორ ან რამდეინიმე კლასს (კატეგორიას) შორის სწორი პასუხის პროგნოზირებაა.** ჩვენი მაგალითის მიზანი, რომ ყოფილიყო გამოგვეცნო ზუსტად რამდენ წუთს დაიგვიანებდა რეისი, რეგრესიული ამოცანა იქნებოდა. **ანუ რეგრესიული ტიპის მოდელები პროგრნოზირებენ უწყვეტ მნიშვნელობებს.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ofYloxFh5tz"
      },
      "source": [
        "##### 1.4.2.2 დაკვირვების გარეშე ალგორითმები\n",
        "დაკვრივების გარეშე ალგორითმები შედარებით აბსტრაქტულია. აქ არც ჩვენ და არც კომპიუტერმა “სწორი” პასუხები არ ვიცით. შესაბამისად ალგორითმებიც აღწერითი ხასიათისაა და დაკვირვების გარეშე ფუნქციონირებენ. კლასტერირების შემთხვევაში (რომელიც ყველაზე ხშირად გამოყენებადი და გავრცელებულია) ალგორითმის მიზანი, მრავალცვლადიანი მონაცემების გარკვეული **მსგავსების მიხედვით დაჯგუფებაა.**\n",
        "\n",
        "Კლიენტების სეგმენტაცია Სხვა მრავალ ამოცანასთან ერთად წარმოადგენს, ერთ-ერთი ყველაზე გავრცელებული ამოცანას, რომელიც კლასტერირების ალგორითმებით იჭრება. Სეგმენტაცია შეიძლება იყოს დემოგრაფიული, ქცევითი, გეოგრაფიული და ა.შ. ცვალდებით. Მიზანი კი ერთგვაროვანი კლიენტების დაჯგუფება და მათზე მეტად პერსონიზირებული კამპანიების წარმოებაა. \n",
        "\n",
        "კლასტერირების გარდა დაკვირვების გარეშე მოდელების ყველაზე მსხვილი მიმართულება ასოციაციის ალგორითმებია. Სავარაუდოდ მკითხველების უმეტესობას შეხვედრია ამაზონზე პროდუქტის გვედრზე ყოფნისას შემდეგი ჩანაწერი: “ამ პროდქუტთან ერთად ყველაზე ხშირად X პროდუქტს ყიდულობენ მომხმარებლები”. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUH619p_h5tz"
      },
      "source": [
        "![5.%20amazon.jpeg](attachment:5.%20amazon.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QY1EFatbh5t0"
      },
      "source": [
        "ან შესაძლებელია ლუდი და “პამპერსის” ლეგენდაც გსმენიათ (პამპერსის საყიდლად წასული ახალგაზრდა მამები ხშირად ყიდულობნენ ლუდსაც, რის აღმოჩენის შემდეგაც მათი მაღაზიაში ერთმანეთის გვერდით განთავსება გადაწყვიტეს გაყიდვების გასაზრდელად). Სხვა სიტყვებით, რომ ვთქვათ **ასოციაციის ალგორითმი ეძებს ისეთ პროდუქტებს რომელებიც ერთამნეთის გაყიდვას უწყობენ ხელს / ერთად ყველაზე ხშირად იყიდებიან.**  \n",
        "\n",
        "აქვე მცირედი გადახვევა თუ რა ღირებულების მომტანია რეალურ გარემოში: ასოციაციის ალგორითმები ხშირად რეკომენდაციების სისტემებში გამოიყენება. Რეკომენდაციების სისტემები კი (რაზეც მოგვიანებით ცალკე თავიც იქნება მიძღვნილი) სხვადასხვა შეფასებებებით “ამაზონის” შემოსალვების 35% აგენერირებენ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htsmE0K-h5t0"
      },
      "source": [
        "### 1.5 Მონაცემებზე დაფუძნებული ამოცანის ციკლი"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3ZLbE7Dh5t0"
      },
      "source": [
        "ყველაფერი რაც აქამდე ვისაუბრეთ, ერთი დიდი ციკლის, მონაცემებზე დაფუძნებული ამოცანის, ნაწილია. Ხშირად გვიჩნდება ცდუნება, რომ  ამოცანის გადაჭრა პირადპირ ალგორითმების შერჩევით დავიწყოთ და ვნახოთ შედეგი. თუმცა სწორი გზა რა თქმა უნდა ამოცანიის შინაარსობრივი გააზრებით დაწყებაა. პრობლემის პირველად გაცნობას ყოველთვის მოსდევს მონაცემების კვლევა. Პროექტის ამ ეტაპზე აუცილებლად ჩნდება დამატებითი კითხვები ამოცანის შინაარსთან დაკავშირებით და მასთან მიბრუნება მთლიანი პროცესის მიკრო ციკლია."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbHQCHr0h5t0"
      },
      "source": [
        "![6.%20data%20Cycle.png](attachment:6.%20data%20Cycle.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiEkXBnIh5t0"
      },
      "source": [
        "Მოდელისთვის მონაცემების მომზადება (რასაც ცალკე ქვეთავებად ვისწავლით წიგნის შემდგომ ნაწილებში) იწყება მხოლოდ მას შემდეგ, რაც ამოცანის შინაარსთან და მონაცემებთან საკამრისი კომფორტი გაგვაჩნია. ეს კი მოდელირებასთან ერთად  მთლიანი პროცესის კიდევ ერთი მიკრო ციკლია.\n",
        "\n",
        "Პირველი მოდელის რეზუტლტატი თითქმის არასდროს არის სახარბიელო. შესაბამისად მისი შედეგის გაანალიზებისას ხშირად ხდება ზუსტადაც ამოცანის საწყის ეტაპზე, შინაარსობრივ გააზრებაზე, დაბრუნება. სასურველი რეზულტატი მხოლოდ ამ ციკლის რამდენჯერმე და საფუძვლიანად განმეორების შედეგად დგება. მხოლოდ მთელი ამ პროცესის რამდენჯერმე განმეორება გვაძლევს მოდელის სიზუსტესა და მდგრადობაში დარწმუნების საფუძველს, რასაც პროცესის ბოლო საფეხური, მოდელის რეალურ გარემოში დანერგვა, მოსდევს."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnwig9iAh5t0"
      },
      "source": [
        "### 1.6 პირველი შეხება, “მაგიურ”, მანქანურ დასწავლასთან\n",
        "თავის ყველაზე საინტერესო, პრაქტიკულ, ნაწილთანაც მოვედით. აქ თქვენივე ხელებით შეძლებთ, ორი არც თუ ისე მარტივი ამოცანის გადაჭრას და დარწმუნდებით, რომ მანქანური დასწავლა მართლაც არ არის ჯადოქრობა!\n",
        "\n",
        "დღეს ნამდვილად აღარ არის მანქანური დასწავლის ალგორითმების გამოყენება ისეთი რთული, როგორც ის 5 და 10 წლის წინ იყო. თუმცა ისეთი მარტივიც არ არის, რომ პირველსავე თავში წარმატებით შევძლოთ მისი გამოყენება. სწორად ამიტომ დახმარებისთვის ავტომატური მანქანური დასწავლის (AutoML) ბიბლიოთეკას მივმართავთ.\n",
        "\n",
        "**ავტომატური მანქანური დასწავლა (AutoML) არის რეალური პრობლემების მანქანური დასწავლის პროცესების გამოყენებით გადაჭრის ავტომატიზაცია.** მისი გამოყენებისთვის ყოველთვის ნამდვილად არ არის საჭირო იყოთ მონაცემთა მეცნიერი ან კარგად გესმოდეთ კოდის წერა. ხშირ შემთხვევაში ასეთ პლატფორმებს ძალიან ინტუიტიური და მარტივად გამოსაყენებელი ინტერფეისები აქვთ. თუმცა გამომდინარე იქედან, რომ ყველა ასეთი პლატფორმა ფასიანია, როგორც ზემოთ აღვნიშნეთ ჩვენ AutoML-ის, უფასო ბიბლიოთეკას, და არა პლატფორმას, გამოვიყენებთ.\n",
        "\n",
        "*შენიშვნა: თუ თქვენ ამ კოდის მხოლოდ წაკითხვა არ გაკმაყოფილებთ (რისი ძალიან დიდი იმედიც გვაქვს) და გსურთ მისი გაშვება, ამისათვის თქვენს კომპიუტერზე Jupyter Notebook-ის დაყენე დაგჭირდებათ (გირჩევთ Anaconda დააყენოთ, სადაც Jupyter-იც იქნება) ან კიდევ უფრო მარტივად Google-ის ანგარიში და Google Colab-ზე ამ ნოუთბუქის Github-ით იმპორტიც საკმარისი იქნება.*\n",
        "\n",
        "ცხრილურ მონაცემებთა მომუშავე ერთ-ერთი ასეთი ავტომატიზირებული მანქანური დასწავლის ბიბლიოთეკა არის **autogluon**. ეს გენიალური ბიბლითეკა AWS-ის გუნდის მიერაა შემუშავებული და მისი დახმარებით სულ რაღაც 5-10 ხაზიანი კოდის დაწრითაა შესაძლებელი სასურველი შედეგების მიღება.\n",
        "\n",
        "*შენიშვნა: ამ ქვეთავში ბევრ ისეთ ბრძანებას შეხვდებით, რომელიც მკითხველების უმეტესობისთვის უცხო იქნება. ამან არ შეგაშინოთ, წიგნის მომდევნო თავებში ყველაფერს დეტალურად დავფარავთ*\n",
        "\n",
        "აღნიშნული ბიბლიოთეკის გამოსაყენებლად პირველ რიგში მისი დაყენება დაგვჭირდება, რაც შემდეგი ბრძანებებითაა შესაძლებელი:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pkykRW-yh5t0"
      },
      "outputs": [],
      "source": [
        "!pip install -U pip\n",
        "!pip install -U setuptools wheel\n",
        "!pip install -U \"mxnet<2.0.0\"\n",
        "!pip install autogluon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnZooDmAh5t1"
      },
      "source": [
        "მას შემდეგ რაც დავაყენეთ ბიბლიოთეკა, აუცილებელია მისი სამუშაო გარემოში შემოტანა შემდეგი ბრძანებებით:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUqp-HfAh5t1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd #ბიბლიოთეკა ცხრილების წასაკითხად \n",
        "from autogluon.tabular import TabularDataset, TabularPredictor #autogluon–ს ცხრილებზე სამუშაო ბიბლიოთეკა\n",
        "from sklearn.model_selection import train_test_split #მონაცემების სატესტო და საწვრთნელ ნაწილებად გახლეჩის ბიბლიოთეკა"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM5skJtFh5t1"
      },
      "source": [
        "#### 1.6.1 კლასიფიკაციის ამოცანა"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOgW3h7Fh5t1"
      },
      "source": [
        "როგორც წინა აბზაცებში აღვნიშნეთ, ამოცანის გადაჭრა მისი შინაარსობრივი გააზრებით იწყება. სწორად ამიტომ ძალიან მოკლედ და მარტივად აღვწეროთ რა პობლემას ვეჭიდებით: ამოცანის მიზანია გარკვეული ინფორმაციით თითოეულ ადამიანზე ვიპროგნოზოთ გადარჩებოდა თუ არა ის ტიტანის ტრაგედისას:\n",
        "\n",
        "   * PassengerId - მგზავრის ID\n",
        "   * Pclass - კაბინის კლასი\n",
        "   * Name - მგზავრის სახელი\n",
        "   * Sex - სქესი\n",
        "   * Age - ასაკი\n",
        "   * SibSp - დების/ძმების/მეუღლის რაოდენობა გემზე\n",
        "   * Parch - მშობლების/შვილების რაოდენობა გემზე\n",
        "   * Ticket - ბილეთის ნომერი\n",
        "   * Fare - ბილეთის ფასი\n",
        "   * Cabin - კაბინის სახელი\n",
        "   * Embarked - ჩასხდომის პორტი\n",
        "   \n",
        "სხვა სიტყვებით რომ ვთქვათ, თითოეულ ადამიანზე მოდელს ვაწვდით ამ ინფორმაციას. ასევე ვაწვდით გადარჩა თუ არა ადამიანი და ვავალებთ კანონზომიერებების პოვნას. რათა შემდგომ მხოლოდ ზემოთ ჩამოთვილი ინფორმაციით იპროგნოზოს გადარჩება თუ არა ადამიანი.    \n",
        "   \n",
        "პასუხები კი **Survived** ცვალდშია მითითებული, სადაც 1-ნიშნავს გარადჩენას, 0-დაღუპვას.\n",
        "\n",
        "ამ მონაცემების სამუშაო გერემოში შემოსატანა და მისი პირველი 3 ჩანაწერის გამოსატანად კი შემდეგი ბრძანებებია საჭირო:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9bpXasO7h5t1",
        "outputId": "e96a1cae-eed5-45a0-e262-15e8e312ac9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "\n",
              "                                                  Name     Sex   Age  SibSp  \\\n",
              "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0      1   \n",
              "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  "
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_class = pd.read_csv('titanic.csv') #მონაცემების სამუშაო გარემოში შემოტანა\n",
        "df_class.head(3) #შემოტანილი მონაცემის პირველი 3 ჩანაწერის გამოჩენა"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdshhw6kh5t2"
      },
      "source": [
        "ზოგადად ნებისმიერი მანქანური დასწავლის მოდელირების დაწყებამდე საჭიროა მონაცემების \"სავარჯიშო\" და \"სატესტო\" ნაწილებად დახლეჩვა, რათა დარწმუნებულები ვიყოთ მოდელის მიუკერძოებულობაში (რა თქმა უნდა ამაზეც მომდევნო თავებში დეტალურად მოგიყვებით). შესაბამისად შემდეგი ბრძანება მთლიან მონაცემებს გახლეჩს 80%-20% პროპორციით (სავაჯიშო/სასწავლი ნაწილი 80%, სატესტო ნაწილი 20%):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwZHjGCzh5t2"
      },
      "outputs": [],
      "source": [
        "train_class, test_class = train_test_split(df_class, test_size = 0.2, random_state=50) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4DSVjWlh5t2"
      },
      "source": [
        "ასევე აუცილებელია შემოვიღოთ რაიმე მეტრიკა, რის დახმარებითად გავზომავთ მოდელის წარმადობას."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l4eSfa_Fh5t2"
      },
      "outputs": [],
      "source": [
        "metric_class = 'accuracy'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lkq6s9iVh5t2"
      },
      "source": [
        "ვუთხრათ მოდელს, რომელი ის ცვლადი მთელი ცხრილიდან, რის პროგნოზირებაც გვინდა:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tpkmg35-h5t2"
      },
      "outputs": [],
      "source": [
        "label_class = 'Survived'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaEfxd5gh5t2"
      },
      "source": [
        "გადავიყვანოთ მონაცემები autogluon–თვის მისაღებ ფორმატში:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4naAi3VMh5t2"
      },
      "outputs": [],
      "source": [
        "train_data_class = TabularDataset(train_class) \n",
        "test_data_class = TabularDataset(test_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYJUiNs9h5t2"
      },
      "source": [
        "და აი ისიც, კოდი რომელიც ჩვენ პირველ მოდელს გაუშვებს:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "eBYuckHLh5t3"
      },
      "outputs": [],
      "source": [
        "predictor_class = TabularPredictor(label = label_class, eval_metric = metric_class) \\\n",
        "            .fit(train_data_class, time_limit = 300)\n",
        "\n",
        "# label-ში ვუთითებთ საპროგნოზო ცვლადის სახელს (ზემოთ ჩვენ მასაც label დავარქვით)\n",
        "# eval_metric-ში ვუთითებთ მოდელის წარმადობის შესაფასებელ მეტრიკას (ზემოთ  metric დავარქვით)\n",
        "# time_limit - ნიშნავს იმ წამების რაოდენობას რაც გვსურს რომ დაიხარჯოს მოდელის აგებაზე/ოპტიმიზაციაზე.\n",
        "# რაც უფრო დიდ დროს ვუთითებთ მით მეტია შესაძლებლობა მოდელის სიზუსტის, თუმცა აქ სიამტივისთვის 300 წამიც გვეყოფა"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qM_tcMKnh5t3"
      },
      "source": [
        "დიახ, ჩვენი პირველი მოდელი უკვე მზადააა. ისღა დაგვრჩენია შევამოწმოდ ჩვენს გადანახულ, სატესტო, მონაცემებზე და ვნახოთ რამდენად კარგად შეძლო დაკისრებული დავალების შესრულება:\n",
        "\n",
        "*შენიშვნა: ქვემოთ მოცემულ კოდს, ჩვენს მიერ არჩეული მეტრიკის გარდა (accuracy), კიდევ ბევრი სხვა მეტრიკის შედეგიც გამოაქვს, თუმცა ამ ეტაპზე ყურადღებას ნუ მივაქცევთ. მეტრიკებზე სულაც ცალკე თავი გვაქვს მიძღვნილი.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "jElYAJOsh5t3",
        "outputId": "96f8f36b-3ae2-4ec0-f557-bfcf25313583"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation: accuracy on test data: 0.7988826815642458\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"accuracy\": 0.7988826815642458,\n",
            "    \"balanced_accuracy\": 0.7750698146737751,\n",
            "    \"mcc\": 0.6079964751009972,\n",
            "    \"roc_auc\": 0.8805534399593806,\n",
            "    \"f1\": 0.71875,\n",
            "    \"precision\": 0.92,\n",
            "    \"recall\": 0.5897435897435898\n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7988826815642458"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor_class.evaluate(test_data_class)['accuracy']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9AGTq6KAh5t3"
      },
      "source": [
        "ვხედავთ, რომ ის მეტრიკა (accuracy) რითიც ვთხოვეთ შეფასება 0.7989-ის ტოლია. ეს კი იმას ნიშნავს რომ 79.89% შემთხვევაში მოდელმა სწორად გამოიცნო გადარჩებოდა თუ არა ადამიანი ტიტანიკის ტრაგედიისას. შეიძლება ითქვას, რომ მშვენიერი რეზულტატია, განსაკუთრებით ასეთი მცირე და ზედაპირული ძალისხმევის შედეგად."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x1f8KfYh5t3"
      },
      "source": [
        "#### 1.6.1 რეგრესიული ამოცანა"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWYnJVAGh5t3"
      },
      "source": [
        "დაპირებული, მეორე ამოცანა რეგრესიული ტიპისაა, ანუ ამ შემთხვევაში მოდელს ზუსტი (უწყვეტი) მნიშვნელობის გამოცნობას დავავალებთ: მოცემული გვაქვს სადაზღვევო ხარჯები და იმ ადამიანების შესახებ რამდენიმე ცვლადი ვიზეც მოხდა ამ ხარჯების გაწევა:\n",
        "\n",
        "   * age - ასაკი\n",
        "   * sex - სქესი\n",
        "   * bmi - სხეულის მასის ინდექსი\n",
        "   * children - დაზღვევაში ჩართული შვილების რაოდენობა\n",
        "   * smoker - არის თუ არა მწეველი\n",
        "   * region - საცხოვრებელი რეგიონი\n",
        "   \n",
        "ხოლოს საპროგნოზო ცვლადი, როგორც ზემოთ აღვნიშნეთ არის დანახარჯის რაოდენობა - **charges**\n",
        "\n",
        "*შენიშვნა: მიუხედავად იმისა, რომ ამოცანა არის რეგრესიული ხასიათის, autogluon-ის ერთ-ერთი მთავარი ღირებულება ისაა, რომ თვითონ ხვდება რა ტიპის პრობლემასთან აქვს საქმე. შესაბამისად ის ნაბიჯები რაც მოდელის გაშვების ჩათვლით დაგვჭირდება, იქნება წინა მაგალითის ანალოგიური.*\n",
        "\n",
        "მონაცემების სამუშაო გარემოში შემოტანა და მისი პირველი 3 ჩანაწერის გამოტანა:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wH4HgcgZh5t3",
        "outputId": "e7531414-d54c-4be5-e802-580474730de9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>children</th>\n",
              "      <th>smoker</th>\n",
              "      <th>region</th>\n",
              "      <th>charges</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19</td>\n",
              "      <td>female</td>\n",
              "      <td>27.90</td>\n",
              "      <td>0</td>\n",
              "      <td>yes</td>\n",
              "      <td>southwest</td>\n",
              "      <td>16884.9240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>18</td>\n",
              "      <td>male</td>\n",
              "      <td>33.77</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>1725.5523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28</td>\n",
              "      <td>male</td>\n",
              "      <td>33.00</td>\n",
              "      <td>3</td>\n",
              "      <td>no</td>\n",
              "      <td>southeast</td>\n",
              "      <td>4449.4620</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   age     sex    bmi  children smoker     region     charges\n",
              "0   19  female  27.90         0    yes  southwest  16884.9240\n",
              "1   18    male  33.77         1     no  southeast   1725.5523\n",
              "2   28    male  33.00         3     no  southeast   4449.4620"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_reg = pd.read_csv('insurance.csv') #მონაცემების სამუშაო გარემოში შემოტანა\n",
        "df_reg.head(3) #შემოტანილი მონაცემის პირველი 3 ჩანაწერის გამოჩენა"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63XhU7Rwh5t3"
      },
      "source": [
        "სავარჯიშო/საწვრთელ და სატესტო მონაცემებად გახლეჩვა:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aa_htpOrh5t3"
      },
      "outputs": [],
      "source": [
        "train_reg, test_reg = train_test_split(df_reg, test_size = 0.2, random_state = 50) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP2zUZW6h5t4",
        "outputId": "6362fd6f-4718-4f05-e716-861e6b199009"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13990.39168537313"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_reg['charges'].mean() # სატესტო ცხრილის საპრონგნოზო ცვლადის, სადაზღვევო დანახარჯის, საშუალოს გამოტანა, რომელიც\n",
        "                       # მოდელის შესაფასებლად დაგვჭირდება"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMrQmvL3h5t4"
      },
      "source": [
        "მთავარი განსხვავება მეტრიკის განსაზღვრისას იქნება, რადგან რეგრესიული და კლასიფიკაციის მოდელების შესაფასებლად რადიკალურად განსხვავებული მიდგომაა საჭირო."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx492Uedh5t4"
      },
      "outputs": [],
      "source": [
        "metric_reg = 'mean_absolute_error' #აბსოლუტური საშუალო გადახრის მეტრიკა"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7KkpOjJh5t4"
      },
      "source": [
        "საპროგნოზო ცვლადის მითითება"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9AGov_6h5t4"
      },
      "outputs": [],
      "source": [
        "label_reg = 'charges'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-uLgbJ2oh5t4"
      },
      "source": [
        "მონაცემების autogluon–თვის მისაღებ ფორმატში გადაყვანა:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "qIE1My4uh5t4"
      },
      "outputs": [],
      "source": [
        "train_data_reg = TabularDataset(train_reg) \n",
        "test_data_reg = TabularDataset(test_reg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4k8FSUph5t4"
      },
      "source": [
        "მოდელის სწავლება, კვალვაც მარტივი ერთ-ხაზიანი კოდით ხდება:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "IxE8ssFch5t4"
      },
      "outputs": [],
      "source": [
        "predictor_reg = TabularPredictor(label = label_reg, eval_metric = metric_reg) \\\n",
        "                .fit(train_data_reg, time_limit = 300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxMjlaiUh5t5"
      },
      "source": [
        "გადანახულ/სატესტო მონაცემებზე მოდელის წარმადობის/სიზუსტის შემოწმება:\n",
        "\n",
        "*შენიშვნა: ქვემოთ მოცემულ კოდს, ჩვენს მიერ არჩეული მეტრიკის გარდა (mean_absolute_error), კიდევ ბევრი სხვა მეტრიკის შედეგიც გამოაქვს, თუმცა ამ ეტაპზე ყურადღებას ნუ მივაქცევთ. მეტრიკებზე სულაც ცალკე თავი გვაქვს მიძღვნილი.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ueC3iNuh5t5",
        "outputId": "e7e1f19c-ca8b-489d-f0b0-cfe7e1256cf2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluation: mean_absolute_error on test data: -2169.0555191760436\n",
            "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
            "Evaluations on test data:\n",
            "{\n",
            "    \"mean_absolute_error\": -2169.0555191760436,\n",
            "    \"root_mean_squared_error\": -4371.4560319730645,\n",
            "    \"mean_squared_error\": -19109627.83947369,\n",
            "    \"r2\": 0.8807821282217947,\n",
            "    \"pearsonr\": 0.9388401466394608,\n",
            "    \"median_absolute_error\": -988.5785021484376\n",
            "}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'mean_absolute_error': -2169.0555191760436,\n",
              " 'root_mean_squared_error': -4371.4560319730645,\n",
              " 'mean_squared_error': -19109627.83947369,\n",
              " 'r2': 0.8807821282217947,\n",
              " 'pearsonr': 0.9388401466394608,\n",
              " 'median_absolute_error': -988.5785021484376}"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predictor_reg.evaluate(test_data_reg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1VwUzUnh5t5"
      },
      "source": [
        "მიღებული შედეგებით ვხედავთ რომ საშუალო აბსოლუტური ცდომილება არის 2169. აღნიშნული მეტრიკა, პროგრნოზირებულ და რეალურ მნიშნვლნელობებს შორის საშუალო აბსოლუტურ გადახრას გვიჩვენებს. მისი მნიშნველობის ინტერპრეტაციის გასამარტივებლად, შეგვიძლია მიღებული შედეგი საპროგნოზო ცვლადის რეალური საშუალოთი დავანორმალიზოთ (იმ საშუალოთ ზემოთ რომ დავთვალეთ): 1 – (2169 / 13990) = 0.845, რაც უხეშად, მოდელის, 84.5%–იან სიზუსტეში ითარგმნება.\n",
        "\n",
        "ზემოთ მოცემული ორივე მაგალითი ზედაპირული და შეიძლება ითქვას საილუსტრაციო ხასითისაა. გვიდოდა გვეჩვენებინა, რომ ზოგ შემთხვევაში მართლაც რამდენიმე ხაზიანი კოდითაც არის შესაძლებელი დამაკმაყოფილებელი შედეგის მიღება. რა თქმა უნდა სწორი იქნებოდა ჯერ აღწერითი და დიაგნოსტიკური ანალიზი ჩაგვეტარებინა, მოცემულ ინფორმაციაზე დაყრდნობით გამოგვეყვანა ახალი ცვლადები, მოგვეძიებინა დამატებითი ინფორმაცია და კიდევ მრავალი ნაბიჯი გაგვევლო ოპტიმალური შედეგის მისაღებად. ყველა ამ ნაბიჯს კი დეტალურად მომდევნო თავებში გავივლით. ჩვენი მიზანიც ეს არის, რომ წიგნის ბოლოს თქვენ სრულყოფილად შეძლოთ მონაცემებზე დაფუძნებული ამოცანების დამოუკიდებლად გადაჭრა."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}